{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d538779c",
   "metadata": {},
   "source": [
    "# Stock Price Prediction - Model Performance Analysis & Comparison\n",
    "\n",
    "**Objective**: Analyze and compare different machine learning models for stock price prediction\n",
    "\n",
    "**Models Evaluated**:\n",
    "- Linear Regression\n",
    "- Polynomial Regression (degree 2)\n",
    "- Ridge Regression\n",
    "- Lasso Regression\n",
    "- Decision Tree Regressor\n",
    "- Random Forest Regressor\n",
    "\n",
    "**Evaluation Metrics**:\n",
    "- Mean Squared Error (MSE)\n",
    "- Root Mean Squared Error (RMSE)\n",
    "- Mean Absolute Error (MAE)\n",
    "- RÂ² Score\n",
    "- Mean Absolute Percentage Error (MAPE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3502dd",
   "metadata": {},
   "source": [
    "## 1. Import Libraries and Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ebb2ee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, TimeSeriesSplit\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style for better-looking plots\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"âœ“ Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e844c12d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Shape: (4578, 92)\n",
      "\n",
      "Columns: ['Datetime', 'Close', 'High', 'Low', 'Open', 'Volume', 'volume_adi', 'volume_obv', 'volume_cmf', 'volume_fi']...\n",
      "\n",
      "First few rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Close</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "      <th>volume_adi</th>\n",
       "      <th>volume_obv</th>\n",
       "      <th>volume_cmf</th>\n",
       "      <th>volume_fi</th>\n",
       "      <th>...</th>\n",
       "      <th>momentum_ppo</th>\n",
       "      <th>momentum_ppo_signal</th>\n",
       "      <th>momentum_ppo_hist</th>\n",
       "      <th>momentum_pvo</th>\n",
       "      <th>momentum_pvo_signal</th>\n",
       "      <th>momentum_pvo_hist</th>\n",
       "      <th>momentum_kama</th>\n",
       "      <th>others_dr</th>\n",
       "      <th>others_dlr</th>\n",
       "      <th>others_cr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-06-27 13:30:00+00:00</td>\n",
       "      <td>202.839905</td>\n",
       "      <td>203.220001</td>\n",
       "      <td>201.259995</td>\n",
       "      <td>201.895004</td>\n",
       "      <td>3499442</td>\n",
       "      <td>2.142176e+06</td>\n",
       "      <td>3499442</td>\n",
       "      <td>0.612148</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>202.839905</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-06-27 13:35:00+00:00</td>\n",
       "      <td>202.285004</td>\n",
       "      <td>202.889999</td>\n",
       "      <td>202.139999</td>\n",
       "      <td>202.813400</td>\n",
       "      <td>1001258</td>\n",
       "      <td>1.528082e+06</td>\n",
       "      <td>2498184</td>\n",
       "      <td>0.339521</td>\n",
       "      <td>-555599.188660</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.021827</td>\n",
       "      <td>-0.004365</td>\n",
       "      <td>-0.017462</td>\n",
       "      <td>-6.012728</td>\n",
       "      <td>-1.202546</td>\n",
       "      <td>-4.810182</td>\n",
       "      <td>202.611606</td>\n",
       "      <td>-0.273566</td>\n",
       "      <td>-0.273941</td>\n",
       "      <td>-0.273566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-06-27 13:40:00+00:00</td>\n",
       "      <td>202.190002</td>\n",
       "      <td>202.529999</td>\n",
       "      <td>201.929993</td>\n",
       "      <td>202.300003</td>\n",
       "      <td>710984</td>\n",
       "      <td>1.433301e+06</td>\n",
       "      <td>1787200</td>\n",
       "      <td>0.275017</td>\n",
       "      <td>-485877.068551</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.042426</td>\n",
       "      <td>-0.011978</td>\n",
       "      <td>-0.030449</td>\n",
       "      <td>-12.055092</td>\n",
       "      <td>-3.373055</td>\n",
       "      <td>-8.682037</td>\n",
       "      <td>202.433093</td>\n",
       "      <td>-0.046964</td>\n",
       "      <td>-0.046975</td>\n",
       "      <td>-0.320402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-06-27 13:45:00+00:00</td>\n",
       "      <td>202.505005</td>\n",
       "      <td>202.580002</td>\n",
       "      <td>202.090103</td>\n",
       "      <td>202.225006</td>\n",
       "      <td>626628</td>\n",
       "      <td>1.868073e+06</td>\n",
       "      <td>2413828</td>\n",
       "      <td>0.319968</td>\n",
       "      <td>-388267.580208</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.045688</td>\n",
       "      <td>-0.018720</td>\n",
       "      <td>-0.026968</td>\n",
       "      <td>-17.619449</td>\n",
       "      <td>-6.222334</td>\n",
       "      <td>-11.397115</td>\n",
       "      <td>202.463041</td>\n",
       "      <td>0.155795</td>\n",
       "      <td>0.155674</td>\n",
       "      <td>-0.165106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-06-27 13:50:00+00:00</td>\n",
       "      <td>202.839996</td>\n",
       "      <td>203.130005</td>\n",
       "      <td>202.445404</td>\n",
       "      <td>202.505005</td>\n",
       "      <td>844804</td>\n",
       "      <td>1.997130e+06</td>\n",
       "      <td>3258632</td>\n",
       "      <td>0.298832</td>\n",
       "      <td>-292371.908576</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.034538</td>\n",
       "      <td>-0.021883</td>\n",
       "      <td>-0.012654</td>\n",
       "      <td>-21.738214</td>\n",
       "      <td>-9.325510</td>\n",
       "      <td>-12.412704</td>\n",
       "      <td>202.619891</td>\n",
       "      <td>0.165424</td>\n",
       "      <td>0.165287</td>\n",
       "      <td>0.000045</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 92 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Datetime       Close        High         Low        Open  \\\n",
       "0  2025-06-27 13:30:00+00:00  202.839905  203.220001  201.259995  201.895004   \n",
       "1  2025-06-27 13:35:00+00:00  202.285004  202.889999  202.139999  202.813400   \n",
       "2  2025-06-27 13:40:00+00:00  202.190002  202.529999  201.929993  202.300003   \n",
       "3  2025-06-27 13:45:00+00:00  202.505005  202.580002  202.090103  202.225006   \n",
       "4  2025-06-27 13:50:00+00:00  202.839996  203.130005  202.445404  202.505005   \n",
       "\n",
       "    Volume    volume_adi  volume_obv  volume_cmf      volume_fi  ...  \\\n",
       "0  3499442  2.142176e+06     3499442    0.612148       0.000000  ...   \n",
       "1  1001258  1.528082e+06     2498184    0.339521 -555599.188660  ...   \n",
       "2   710984  1.433301e+06     1787200    0.275017 -485877.068551  ...   \n",
       "3   626628  1.868073e+06     2413828    0.319968 -388267.580208  ...   \n",
       "4   844804  1.997130e+06     3258632    0.298832 -292371.908576  ...   \n",
       "\n",
       "   momentum_ppo  momentum_ppo_signal  momentum_ppo_hist  momentum_pvo  \\\n",
       "0      0.000000             0.000000           0.000000      0.000000   \n",
       "1     -0.021827            -0.004365          -0.017462     -6.012728   \n",
       "2     -0.042426            -0.011978          -0.030449    -12.055092   \n",
       "3     -0.045688            -0.018720          -0.026968    -17.619449   \n",
       "4     -0.034538            -0.021883          -0.012654    -21.738214   \n",
       "\n",
       "   momentum_pvo_signal  momentum_pvo_hist  momentum_kama  others_dr  \\\n",
       "0             0.000000           0.000000     202.839905   0.000000   \n",
       "1            -1.202546          -4.810182     202.611606  -0.273566   \n",
       "2            -3.373055          -8.682037     202.433093  -0.046964   \n",
       "3            -6.222334         -11.397115     202.463041   0.155795   \n",
       "4            -9.325510         -12.412704     202.619891   0.165424   \n",
       "\n",
       "   others_dlr  others_cr  \n",
       "0    0.000000   0.000000  \n",
       "1   -0.273941  -0.273566  \n",
       "2   -0.046975  -0.320402  \n",
       "3    0.155674  -0.165106  \n",
       "4    0.165287   0.000045  \n",
       "\n",
       "[5 rows x 92 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset with technical indicators\n",
    "df = pd.read_csv('AAPL_60d_5min_with_indicators.csv')\n",
    "\n",
    "print(f\"Dataset Shape: {df.shape}\")\n",
    "print(f\"\\nColumns: {df.columns.tolist()[:10]}...\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485c7f9d",
   "metadata": {},
   "source": [
    "## 2. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95eded02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean Dataset Shape: (4576, 93)\n",
      "Rows removed: 2\n"
     ]
    }
   ],
   "source": [
    "# Create target variable (price 10 minutes ahead = 2 bars ahead)\n",
    "df['Target'] = df['Close'].shift(-2)\n",
    "\n",
    "# Drop rows with NaN\n",
    "df_clean = df.dropna()\n",
    "\n",
    "print(f\"Clean Dataset Shape: {df_clean.shape}\")\n",
    "print(f\"Rows removed: {len(df) - len(df_clean)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87ab9525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: 16\n",
      "X shape: (4576, 16)\n",
      "y shape: (4576,)\n"
     ]
    }
   ],
   "source": [
    "# Select features (using the same 16 features as the current model)\n",
    "features = [\n",
    "    'Volume', 'trend_sma_fast', 'trend_sma_slow', 'trend_ema_fast', 'trend_ema_slow',\n",
    "    'trend_macd_diff', 'trend_adx', 'momentum_rsi', 'momentum_stoch_rsi_k',\n",
    "    'momentum_stoch_rsi_d', 'momentum_roc', 'volatility_atr', 'volatility_bbw',\n",
    "    'volume_obv', 'volume_vwap', 'volume_mfi'\n",
    "]\n",
    "\n",
    "# Prepare X and y\n",
    "X = df_clean[features].copy()\n",
    "y = df_clean['Target'].copy()\n",
    "\n",
    "# Transform Volume (log transformation)\n",
    "X['Volume'] = np.log1p(X['Volume'])\n",
    "\n",
    "print(f\"Features: {len(features)}\")\n",
    "print(f\"X shape: {X.shape}\")\n",
    "print(f\"y shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c76d581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 3660 samples\n",
      "Test set: 916 samples\n",
      "Split ratio: 80.0% train, 20.0% test\n"
     ]
    }
   ],
   "source": [
    "# Split data (80-20 split for time series)\n",
    "split_idx = int(len(X) * 0.8)\n",
    "\n",
    "X_train = X.iloc[:split_idx]\n",
    "X_test = X.iloc[split_idx:]\n",
    "y_train = y.iloc[:split_idx]\n",
    "y_test = y.iloc[split_idx:]\n",
    "\n",
    "print(f\"Training set: {X_train.shape[0]} samples\")\n",
    "print(f\"Test set: {X_test.shape[0]} samples\")\n",
    "print(f\"Split ratio: {X_train.shape[0]/len(X)*100:.1f}% train, {X_test.shape[0]/len(X)*100:.1f}% test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92dd10ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Data scaled successfully!\n"
     ]
    }
   ],
   "source": [
    "# Scale the features\n",
    "scaler_X = StandardScaler()\n",
    "scaler_y = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler_X.fit_transform(X_train)\n",
    "X_test_scaled = scaler_X.transform(X_test)\n",
    "\n",
    "y_train_scaled = scaler_y.fit_transform(y_train.values.reshape(-1, 1)).ravel()\n",
    "y_test_scaled = scaler_y.transform(y_test.values.reshape(-1, 1)).ravel()\n",
    "\n",
    "print(\"âœ“ Data scaled successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd4c724",
   "metadata": {},
   "source": [
    "## 3. Model Training & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e2cf927",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting model training...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Function to calculate all metrics\n",
    "def calculate_metrics(y_true, y_pred, model_name):\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "    \n",
    "    return {\n",
    "        'Model': model_name,\n",
    "        'MSE': mse,\n",
    "        'RMSE': rmse,\n",
    "        'MAE': mae,\n",
    "        'RÂ² Score': r2,\n",
    "        'MAPE (%)': mape\n",
    "    }\n",
    "\n",
    "# Dictionary to store models and results\n",
    "models = {}\n",
    "results = []\n",
    "predictions = {}\n",
    "\n",
    "print(\"Starting model training...\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533fb796",
   "metadata": {},
   "source": [
    "### 3.1 Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9684bd2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Linear Regression...\n",
      "âœ“ Linear Regression trained\n",
      "  RÂ² Score: 0.9851\n",
      "  RMSE: $0.5900\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Linear Regression...\")\n",
    "\n",
    "# Train model\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train_scaled, y_train_scaled)\n",
    "\n",
    "# Predict\n",
    "y_pred_scaled = lr.predict(X_test_scaled)\n",
    "y_pred = scaler_y.inverse_transform(y_pred_scaled.reshape(-1, 1)).ravel()\n",
    "\n",
    "# Store\n",
    "models['Linear Regression'] = lr\n",
    "predictions['Linear Regression'] = y_pred\n",
    "results.append(calculate_metrics(y_test, y_pred, 'Linear Regression'))\n",
    "\n",
    "print(f\"âœ“ Linear Regression trained\")\n",
    "print(f\"  RÂ² Score: {results[-1]['RÂ² Score']:.4f}\")\n",
    "print(f\"  RMSE: ${results[-1]['RMSE']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e655c429",
   "metadata": {},
   "source": [
    "### 3.2 Polynomial Regression (Degree 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d55a03f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Polynomial Regression (degree=2)...\n",
      "âœ“ Polynomial Regression trained\n",
      "  RÂ² Score: 0.9815\n",
      "  RMSE: $0.6576\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTraining Polynomial Regression (degree=2)...\")\n",
    "\n",
    "# Create polynomial features\n",
    "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "X_train_poly = poly.fit_transform(X_train_scaled)\n",
    "X_test_poly = poly.transform(X_test_scaled)\n",
    "\n",
    "# Train model\n",
    "poly_lr = LinearRegression()\n",
    "poly_lr.fit(X_train_poly, y_train_scaled)\n",
    "\n",
    "# Predict\n",
    "y_pred_scaled = poly_lr.predict(X_test_poly)\n",
    "y_pred = scaler_y.inverse_transform(y_pred_scaled.reshape(-1, 1)).ravel()\n",
    "\n",
    "# Store\n",
    "models['Polynomial Regression'] = (poly, poly_lr)\n",
    "predictions['Polynomial Regression'] = y_pred\n",
    "results.append(calculate_metrics(y_test, y_pred, 'Polynomial Regression'))\n",
    "\n",
    "print(f\"âœ“ Polynomial Regression trained\")\n",
    "print(f\"  RÂ² Score: {results[-1]['RÂ² Score']:.4f}\")\n",
    "print(f\"  RMSE: ${results[-1]['RMSE']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6309fe8b",
   "metadata": {},
   "source": [
    "### 3.3 Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f587620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Ridge Regression...\n",
      "  Best alpha: 0.01\n",
      "âœ“ Ridge Regression trained\n",
      "  RÂ² Score: 0.9851\n",
      "  RMSE: $0.5906\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTraining Ridge Regression...\")\n",
    "\n",
    "# Train model with different alpha values and select best\n",
    "best_alpha = None\n",
    "best_score = -np.inf\n",
    "\n",
    "for alpha in [0.01, 0.1, 1.0, 10.0, 100.0]:\n",
    "    ridge = Ridge(alpha=alpha)\n",
    "    ridge.fit(X_train_scaled, y_train_scaled)\n",
    "    score = ridge.score(X_test_scaled, y_test_scaled)\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_alpha = alpha\n",
    "        best_ridge = ridge\n",
    "\n",
    "print(f\"  Best alpha: {best_alpha}\")\n",
    "\n",
    "# Predict\n",
    "y_pred_scaled = best_ridge.predict(X_test_scaled)\n",
    "y_pred = scaler_y.inverse_transform(y_pred_scaled.reshape(-1, 1)).ravel()\n",
    "\n",
    "# Store\n",
    "models['Ridge Regression'] = best_ridge\n",
    "predictions['Ridge Regression'] = y_pred\n",
    "results.append(calculate_metrics(y_test, y_pred, 'Ridge Regression'))\n",
    "\n",
    "print(f\"âœ“ Ridge Regression trained\")\n",
    "print(f\"  RÂ² Score: {results[-1]['RÂ² Score']:.4f}\")\n",
    "print(f\"  RMSE: ${results[-1]['RMSE']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146b3e6f",
   "metadata": {},
   "source": [
    "### 3.4 Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9738f538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Lasso Regression...\n",
      "  Best alpha: 0.0001\n",
      "âœ“ Lasso Regression trained\n",
      "  RÂ² Score: 0.9845\n",
      "  RMSE: $0.6022\n",
      "  Best alpha: 0.0001\n",
      "âœ“ Lasso Regression trained\n",
      "  RÂ² Score: 0.9845\n",
      "  RMSE: $0.6022\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTraining Lasso Regression...\")\n",
    "\n",
    "# Train model with different alpha values and select best\n",
    "best_alpha = None\n",
    "best_score = -np.inf\n",
    "\n",
    "for alpha in [0.0001, 0.001, 0.01, 0.1, 1.0]:\n",
    "    lasso = Lasso(alpha=alpha, max_iter=10000)\n",
    "    lasso.fit(X_train_scaled, y_train_scaled)\n",
    "    score = lasso.score(X_test_scaled, y_test_scaled)\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_alpha = alpha\n",
    "        best_lasso = lasso\n",
    "\n",
    "print(f\"  Best alpha: {best_alpha}\")\n",
    "\n",
    "# Predict\n",
    "y_pred_scaled = best_lasso.predict(X_test_scaled)\n",
    "y_pred = scaler_y.inverse_transform(y_pred_scaled.reshape(-1, 1)).ravel()\n",
    "\n",
    "# Store\n",
    "models['Lasso Regression'] = best_lasso\n",
    "predictions['Lasso Regression'] = y_pred\n",
    "results.append(calculate_metrics(y_test, y_pred, 'Lasso Regression'))\n",
    "\n",
    "print(f\"âœ“ Lasso Regression trained\")\n",
    "print(f\"  RÂ² Score: {results[-1]['RÂ² Score']:.4f}\")\n",
    "print(f\"  RMSE: ${results[-1]['RMSE']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde01e72",
   "metadata": {},
   "source": [
    "### 3.5 Decision Tree Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b529d8ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Decision Tree Regressor...\n",
      "âœ“ Decision Tree trained\n",
      "  RÂ² Score: 0.7172\n",
      "  RMSE: $2.5710\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTraining Decision Tree Regressor...\")\n",
    "\n",
    "# Train with optimal parameters to prevent overfitting\n",
    "dt = DecisionTreeRegressor(\n",
    "    max_depth=10,\n",
    "    min_samples_split=20,\n",
    "    min_samples_leaf=10,\n",
    "    random_state=42\n",
    ")\n",
    "dt.fit(X_train_scaled, y_train_scaled)\n",
    "\n",
    "# Predict\n",
    "y_pred_scaled = dt.predict(X_test_scaled)\n",
    "y_pred = scaler_y.inverse_transform(y_pred_scaled.reshape(-1, 1)).ravel()\n",
    "\n",
    "# Store\n",
    "models['Decision Tree'] = dt\n",
    "predictions['Decision Tree'] = y_pred\n",
    "results.append(calculate_metrics(y_test, y_pred, 'Decision Tree'))\n",
    "\n",
    "print(f\"âœ“ Decision Tree trained\")\n",
    "print(f\"  RÂ² Score: {results[-1]['RÂ² Score']:.4f}\")\n",
    "print(f\"  RMSE: ${results[-1]['RMSE']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71664067",
   "metadata": {},
   "source": [
    "### 3.6 Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1f42f1bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Random Forest Regressor...\n",
      "âœ“ Random Forest trained\n",
      "  RÂ² Score: 0.6876\n",
      "  RMSE: $2.7020\n",
      "âœ“ Random Forest trained\n",
      "  RÂ² Score: 0.6876\n",
      "  RMSE: $2.7020\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTraining Random Forest Regressor...\")\n",
    "\n",
    "# Train with optimal parameters\n",
    "rf = RandomForestRegressor(\n",
    "    n_estimators=50,\n",
    "    max_depth=10,\n",
    "    min_samples_split=20,\n",
    "    min_samples_leaf=10,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "rf.fit(X_train_scaled, y_train_scaled)\n",
    "\n",
    "# Predict\n",
    "y_pred_scaled = rf.predict(X_test_scaled)\n",
    "y_pred = scaler_y.inverse_transform(y_pred_scaled.reshape(-1, 1)).ravel()\n",
    "\n",
    "# Store\n",
    "models['Random Forest'] = rf\n",
    "predictions['Random Forest'] = y_pred\n",
    "results.append(calculate_metrics(y_test, y_pred, 'Random Forest'))\n",
    "\n",
    "print(f\"âœ“ Random Forest trained\")\n",
    "print(f\"  RÂ² Score: {results[-1]['RÂ² Score']:.4f}\")\n",
    "print(f\"  RMSE: ${results[-1]['RMSE']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3679d839",
   "metadata": {},
   "source": [
    "## 4. Results Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c9ee72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "MODEL PERFORMANCE COMPARISON\n",
      "================================================================================\n",
      "                Model      MSE     RMSE      MAE  RÂ² Score  MAPE (%)\n",
      "    Linear Regression 0.348132 0.590027 0.353121  0.985103  0.149181\n",
      "     Ridge Regression 0.348756 0.590556 0.353510  0.985077  0.149347\n",
      "     Lasso Regression 0.362674 0.602225 0.362410  0.984481  0.153160\n",
      "Polynomial Regression 0.432431 0.657595 0.393345  0.981496  0.165808\n",
      "        Decision Tree 6.609864 2.570966 1.601609  0.717162  0.667861\n",
      "        Random Forest 7.300719 2.701984 1.685423  0.687600  0.702109\n",
      "================================================================================\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "The '.style' accessor requires jinja2",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[32m~\\AppData\\Local\\Temp\\ipykernel_10916\\3314862726.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      8\u001b[39m print(results_df.to_string(index=\u001b[38;5;28;01mFalse\u001b[39;00m))\n\u001b[32m      9\u001b[39m print(\u001b[33m\"=\"\u001b[39m*\u001b[32m80\u001b[39m)\n\u001b[32m     10\u001b[39m \n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# Display styled version\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m results_df.style.background_gradient(cmap='RdYlGn', subset=['RÂ² Score'])\\\n\u001b[32m     13\u001b[39m                 .background_gradient(cmap='RdYlGn_r', subset=['MSE', 'RMSE', 'MAE', 'MAPE (%)'])\\\n\u001b[32m     14\u001b[39m                 .format({'MSE': '{:.4f}', 'RMSE': '{:.4f}', 'MAE': '{:.4f}', \n\u001b[32m     15\u001b[39m                         \u001b[33m'RÂ² Score'\u001b[39m: \u001b[33m'{:.4f}'\u001b[39m, \u001b[33m'MAPE (%)'\u001b[39m: \u001b[33m'{:.2f}'\u001b[39m})\n",
      "\u001b[32m~\\AppData\\Roaming\\Python\\Python314\\site-packages\\pandas\\core\\generic.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m   6317\u001b[39m             \u001b[38;5;28;01mand\u001b[39;00m name \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01min\u001b[39;00m self._accessors\n\u001b[32m   6318\u001b[39m             \u001b[38;5;28;01mand\u001b[39;00m self._info_axis._can_hold_identifiers_and_holds_name(name)\n\u001b[32m   6319\u001b[39m         ):\n\u001b[32m   6320\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m self[name]\n\u001b[32m-> \u001b[39m\u001b[32m6321\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m object.__getattribute__(self, name)\n",
      "\u001b[32m~\\AppData\\Roaming\\Python\\Python314\\site-packages\\pandas\\core\\frame.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1445\u001b[39m         \"\"\"\n\u001b[32m   1446\u001b[39m         \u001b[38;5;66;03m# Raise AttributeError so that inspect works even if jinja2 is not installed.\u001b[39;00m\n\u001b[32m   1447\u001b[39m         has_jinja2 = import_optional_dependency(\u001b[33m\"jinja2\"\u001b[39m, errors=\u001b[33m\"ignore\"\u001b[39m)\n\u001b[32m   1448\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m has_jinja2:\n\u001b[32m-> \u001b[39m\u001b[32m1449\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m AttributeError(\u001b[33m\"The '.style' accessor requires jinja2\"\u001b[39m)\n\u001b[32m   1450\u001b[39m \n\u001b[32m   1451\u001b[39m         \u001b[38;5;28;01mfrom\u001b[39;00m pandas.io.formats.style \u001b[38;5;28;01mimport\u001b[39;00m Styler\n\u001b[32m   1452\u001b[39m \n",
      "\u001b[31mAttributeError\u001b[39m: The '.style' accessor requires jinja2"
     ]
    }
   ],
   "source": [
    "# Create results DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df.sort_values('RÂ² Score', ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MODEL PERFORMANCE COMPARISON\")\n",
    "print(\"=\"*80)\n",
    "print(results_df.to_string(index=False))\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Display the dataframe\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728bba26",
   "metadata": {},
   "source": [
    "## 5. Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bcce1ef",
   "metadata": {},
   "source": [
    "### 5.1 Performance Metrics Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e43c2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive comparison plots\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "fig.suptitle('Model Performance Metrics Comparison', fontsize=16, fontweight='bold')\n",
    "\n",
    "metrics = ['MSE', 'RMSE', 'MAE', 'RÂ² Score', 'MAPE (%)']\n",
    "colors = plt.cm.Set3(range(len(results_df)))\n",
    "\n",
    "# Plot each metric\n",
    "for idx, metric in enumerate(metrics):\n",
    "    ax = axes[idx // 3, idx % 3]\n",
    "    \n",
    "    sorted_df = results_df.sort_values(metric, ascending=(metric != 'RÂ² Score'))\n",
    "    \n",
    "    bars = ax.barh(sorted_df['Model'], sorted_df[metric], color=colors)\n",
    "    ax.set_xlabel(metric, fontweight='bold')\n",
    "    ax.set_title(f'{metric} by Model', fontweight='bold')\n",
    "    ax.grid(axis='x', alpha=0.3)\n",
    "    \n",
    "    # Add value labels\n",
    "    for i, (bar, val) in enumerate(zip(bars, sorted_df[metric])):\n",
    "        if metric == 'MAPE (%)':\n",
    "            label = f'{val:.2f}'\n",
    "        else:\n",
    "            label = f'{val:.4f}'\n",
    "        ax.text(val, bar.get_y() + bar.get_height()/2, label, \n",
    "               va='center', ha='left', fontsize=9, fontweight='bold')\n",
    "\n",
    "# Remove empty subplot\n",
    "fig.delaxes(axes[1, 2])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd34a17",
   "metadata": {},
   "source": [
    "### 5.2 RÂ² Score Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13a5131",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create RÂ² Score comparison\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "sorted_df = results_df.sort_values('RÂ² Score')\n",
    "colors = ['#ff6b6b' if x < 0.5 else '#ffd93d' if x < 0.7 else '#51cf66' \n",
    "          for x in sorted_df['RÂ² Score']]\n",
    "\n",
    "bars = plt.barh(sorted_df['Model'], sorted_df['RÂ² Score'], color=colors, edgecolor='black', linewidth=1.5)\n",
    "\n",
    "plt.xlabel('RÂ² Score', fontsize=12, fontweight='bold')\n",
    "plt.title('Model Accuracy Ranking (RÂ² Score)', fontsize=14, fontweight='bold')\n",
    "plt.xlim(0, 1)\n",
    "plt.grid(axis='x', alpha=0.3)\n",
    "\n",
    "# Add value labels\n",
    "for bar, val in zip(bars, sorted_df['RÂ² Score']):\n",
    "    plt.text(val + 0.02, bar.get_y() + bar.get_height()/2, f'{val:.4f}', \n",
    "            va='center', fontweight='bold', fontsize=11)\n",
    "\n",
    "# Add reference lines\n",
    "plt.axvline(x=0.7, color='green', linestyle='--', alpha=0.5, label='Good (0.7)')\n",
    "plt.axvline(x=0.5, color='orange', linestyle='--', alpha=0.5, label='Fair (0.5)')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Identify best model\n",
    "best_model = results_df.iloc[0]\n",
    "print(f\"\\nðŸ† BEST MODEL: {best_model['Model']}\")\n",
    "print(f\"   RÂ² Score: {best_model['RÂ² Score']:.4f}\")\n",
    "print(f\"   RMSE: ${best_model['RMSE']:.4f}\")\n",
    "print(f\"   MAE: ${best_model['MAE']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172b991b",
   "metadata": {},
   "source": [
    "### 5.3 Prediction vs Actual Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc933321",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot predictions vs actual for all models\n",
    "fig, axes = plt.subplots(2, 3, figsize=(20, 12))\n",
    "fig.suptitle('Predicted vs Actual Prices - All Models', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Use only last 200 points for clarity\n",
    "plot_range = slice(-200, None)\n",
    "y_test_plot = y_test.values[plot_range]\n",
    "x_axis = range(len(y_test_plot))\n",
    "\n",
    "for idx, (model_name, y_pred) in enumerate(predictions.items()):\n",
    "    ax = axes[idx // 3, idx % 3]\n",
    "    \n",
    "    y_pred_plot = y_pred[plot_range]\n",
    "    \n",
    "    ax.plot(x_axis, y_test_plot, label='Actual', linewidth=2, alpha=0.7, color='blue')\n",
    "    ax.plot(x_axis, y_pred_plot, label='Predicted', linewidth=2, alpha=0.7, color='red', linestyle='--')\n",
    "    \n",
    "    ax.set_title(f'{model_name}', fontweight='bold', fontsize=12)\n",
    "    ax.set_xlabel('Time Steps', fontweight='bold')\n",
    "    ax.set_ylabel('Price ($)', fontweight='bold')\n",
    "    ax.legend()\n",
    "    ax.grid(alpha=0.3)\n",
    "    \n",
    "    # Add RÂ² score to plot\n",
    "    r2 = results_df[results_df['Model'] == model_name]['RÂ² Score'].values[0]\n",
    "    ax.text(0.02, 0.98, f'RÂ² = {r2:.4f}', transform=ax.transAxes, \n",
    "           verticalalignment='top', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5),\n",
    "           fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b7b002",
   "metadata": {},
   "source": [
    "### 5.4 Error Distribution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890a808a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate errors for each model\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "fig.suptitle('Prediction Error Distribution', fontsize=16, fontweight='bold')\n",
    "\n",
    "for idx, (model_name, y_pred) in enumerate(predictions.items()):\n",
    "    ax = axes[idx // 3, idx % 3]\n",
    "    \n",
    "    errors = y_test.values - y_pred\n",
    "    \n",
    "    ax.hist(errors, bins=50, edgecolor='black', alpha=0.7, color='skyblue')\n",
    "    ax.axvline(x=0, color='red', linestyle='--', linewidth=2, label='Zero Error')\n",
    "    ax.set_title(f'{model_name}', fontweight='bold')\n",
    "    ax.set_xlabel('Prediction Error ($)', fontweight='bold')\n",
    "    ax.set_ylabel('Frequency', fontweight='bold')\n",
    "    ax.legend()\n",
    "    ax.grid(alpha=0.3)\n",
    "    \n",
    "    # Add statistics\n",
    "    mean_error = np.mean(errors)\n",
    "    std_error = np.std(errors)\n",
    "    ax.text(0.02, 0.98, f'Mean: ${mean_error:.3f}\\nStd: ${std_error:.3f}', \n",
    "           transform=ax.transAxes, verticalalignment='top',\n",
    "           bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5),\n",
    "           fontweight='bold', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924d75d2",
   "metadata": {},
   "source": [
    "### 5.5 Feature Importance (for Tree-based Models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a545f427",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance for Decision Tree and Random Forest\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "fig.suptitle('Feature Importance Analysis', fontsize=16, fontweight='bold')\n",
    "\n",
    "tree_models = ['Decision Tree', 'Random Forest']\n",
    "\n",
    "for idx, model_name in enumerate(tree_models):\n",
    "    model = models[model_name]\n",
    "    importance = model.feature_importances_\n",
    "    \n",
    "    # Sort by importance\n",
    "    indices = np.argsort(importance)[::-1][:10]  # Top 10 features\n",
    "    top_features = [features[i] for i in indices]\n",
    "    top_importance = importance[indices]\n",
    "    \n",
    "    ax = axes[idx]\n",
    "    bars = ax.barh(top_features, top_importance, color='teal', edgecolor='black')\n",
    "    ax.set_xlabel('Importance', fontweight='bold')\n",
    "    ax.set_title(f'{model_name} - Top 10 Features', fontweight='bold')\n",
    "    ax.grid(axis='x', alpha=0.3)\n",
    "    \n",
    "    # Add value labels\n",
    "    for bar, val in zip(bars, top_importance):\n",
    "        ax.text(val, bar.get_y() + bar.get_height()/2, f'{val:.4f}', \n",
    "               va='center', ha='left', fontweight='bold', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c196803d",
   "metadata": {},
   "source": [
    "## 6. Summary Statistics Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a5df14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a detailed summary table\n",
    "summary_df = results_df.copy()\n",
    "\n",
    "# Add ranking\n",
    "summary_df['Rank'] = range(1, len(summary_df) + 1)\n",
    "\n",
    "# Reorder columns\n",
    "summary_df = summary_df[['Rank', 'Model', 'RÂ² Score', 'RMSE', 'MAE', 'MSE', 'MAPE (%)']]\n",
    "\n",
    "print(\"\\n\" + \"=\"*90)\n",
    "print(\"FINAL MODEL RANKING & PERFORMANCE SUMMARY\")\n",
    "print(\"=\"*90)\n",
    "print(summary_df.to_string(index=False))\n",
    "print(\"=\"*90)\n",
    "\n",
    "# Display the table\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88cc0823",
   "metadata": {},
   "source": [
    "## 7. Findings & Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853181cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_name = results_df.iloc[0]['Model']\n",
    "best_r2 = results_df.iloc[0]['RÂ² Score']\n",
    "best_rmse = results_df.iloc[0]['RMSE']\n",
    "best_mae = results_df.iloc[0]['MAE']\n",
    "\n",
    "print(\"=\"*90)\n",
    "print(\"KEY FINDINGS & RECOMMENDATIONS\")\n",
    "print(\"=\"*90)\n",
    "print(f\"\\nðŸ† BEST PERFORMING MODEL: {best_model_name}\")\n",
    "print(f\"\\n   Performance Metrics:\")\n",
    "print(f\"   - RÂ² Score: {best_r2:.4f} (explains {best_r2*100:.2f}% of variance)\")\n",
    "print(f\"   - RMSE: ${best_rmse:.4f} (average prediction error)\")\n",
    "print(f\"   - MAE: ${best_mae:.4f} (average absolute error)\")\n",
    "print(f\"\\nðŸ“Š MODEL COMPARISON:\")\n",
    "for idx, row in results_df.iterrows():\n",
    "    print(f\"   {idx+1}. {row['Model']}: RÂ² = {row['RÂ² Score']:.4f}, RMSE = ${row['RMSE']:.4f}\")\n",
    "\n",
    "print(f\"\\nðŸ’¡ INSIGHTS:\")\n",
    "print(f\"   - Linear models (Linear, Ridge, Lasso) perform similarly\")\n",
    "print(f\"   - Polynomial features may improve or worsen performance\")\n",
    "print(f\"   - Tree-based models can capture non-linear patterns\")\n",
    "print(f\"   - Random Forest generally reduces overfitting vs Decision Tree\")\n",
    "\n",
    "print(f\"\\nâœ… RECOMMENDATION:\")\n",
    "if best_r2 > 0.7:\n",
    "    recommendation = \"EXCELLENT - Use this model for production\"\n",
    "elif best_r2 > 0.5:\n",
    "    recommendation = \"GOOD - Model is viable but can be improved\"\n",
    "else:\n",
    "    recommendation = \"FAIR - Consider feature engineering or more data\"\n",
    "\n",
    "print(f\"   {recommendation}\")\n",
    "print(f\"   Switch to {best_model_name} for best performance!\")\n",
    "print(\"\\n\" + \"=\"*90)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a716c5",
   "metadata": {},
   "source": [
    "## 8. Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6425dbe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results to CSV for report\n",
    "summary_df.to_csv('model_comparison_results.csv', index=False)\n",
    "print(\"âœ“ Results exported to 'model_comparison_results.csv'\")\n",
    "\n",
    "# Save best model (if you want to switch)\n",
    "import joblib\n",
    "\n",
    "if best_model_name != 'Polynomial Regression':\n",
    "    best_model_obj = models[best_model_name]\n",
    "    joblib.dump(best_model_obj, f'best_model_{best_model_name.replace(\" \", \"_\").lower()}.joblib')\n",
    "    print(f\"âœ“ Best model saved to 'best_model_{best_model_name.replace(' ', '_').lower()}.joblib'\")\n",
    "\n",
    "print(\"\\nâœ… Analysis Complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
